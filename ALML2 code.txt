#Implementation
#Hereâ€™s a step-by-step code implementation:

#python Code

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix
from transformers import pipeline, BertTokenizer, BertForSequenceClassification
from transformers import Trainer, TrainingArguments
from datasets import load_dataset, load_metric
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import re

# Load Data
data = pd.read_csv('customer_reviews.csv')

# Preprocess Text
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\d+', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = word_tokenize(text)
    text = [PorterStemmer().stem(word) for word in text if word not in stopwords.words('english')]
    return ' '.join(text)

data['cleaned_review'] = data['review'].apply(preprocess_text)

# Aspect Extraction using a pre-trained NER model
ner_model = pipeline('ner', model='dbmdz/bert-large-cased-finetuned-conll03-english', tokenizer='dbmdz/bert-large-cased-finetuned-conll03-english')

def extract_aspects(text):
    entities = ner_model(text)
    aspects = [entity['word'] for entity in entities if entity['entity'] in ['B-FOOD', 'B-SERVICE', 'B-AMBIENCE', 'B-PRICING', 'B-CLEANLINESS']]
    return ', '.join(aspects)

data['aspects'] = data['cleaned_review'].apply(extract_aspects)

# Train Sentiment Analysis Model
dataset = load_dataset('imdb')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)

encoded_dataset = dataset.map(tokenize_function, batched=True)
encoded_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])

training_args = TrainingArguments(
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    output_dir='./results',
    evaluation_strategy="epoch",
    logging_dir='./logs',
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=encoded_dataset['train'],
    eval_dataset=encoded_dataset['test'],
)

trainer.train()

# Sentiment Prediction
def predict_sentiment(texts):
    sentiments = []
    for text in texts:
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        outputs = model(**inputs)
        prediction = np.argmax(outputs.logits.detach().numpy())
        sentiments.append(prediction)
    return sentiments

data['sentiment'] = predict_sentiment(data['cleaned_review'])

# Evaluation
y_true = data['actual_sentiment']
y_pred = data['sentiment']
accuracy = accuracy_score(y_true, y_pred)
precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Insights Report
aspects_counts = data['aspects'].value_counts()
sentiment_distribution = data['sentiment'].value_counts()

print('Aspects Distribution:')
print(aspects_counts)
print('Sentiment Distribution:')
print(sentiment_distribution)

# Save the outputs
data[['aspects', 'sentiment']].to_csv('aspect_sentiment_output.csv', index=False)

#Summary
Aspect Extraction: Utilized pre-trained NER models to extract predefined aspects.
Sentiment Classification: Implemented a fine-tuned BERT model for sentiment classification.
Evaluation: Assessed aspect extraction and sentiment classification accuracy, precision, recall, and F1 scores.
Insights: Provided actionable insights based on aspect and sentiment distributions.
Submission:

#Model Code
Aspect Extraction and Sentiment Classification Outputs
Final Insights Report
